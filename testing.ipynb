{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.get_completion_with_function import get_completion_with_function\n",
    "from prompts.create_extract_tech_prompt import create_extract_tech_prompt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "{\"role\":\"assistant\", \"content\":\"Hello! I'm Archie the Architect. I can help you determine what technologies you need for your data architecture. Could you please tell me a bit about your project?\"},\n",
    "{\"role\":\"user\",\"content\":\"i want to visualize my marketing data\"},\n",
    "{\"role\":\"assistant\",\"content\":\"That sounds like a great project! To start, could you please tell me what kind of data you are working with? Is it structured, semi-structured, or unstructured?\"},\n",
    "{\"role\":\"user\",\"content\":\"structured\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Great! Structured data is easier to work with. Now, could you tell me about your latency requirements? In other words, how quickly do you need to access your data after it's been collected?\"},\n",
    "{\"role\":\"user\",\"content\":\"daily\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Understood. Now, are you planning on doing any predictive analytics, like machine learning, with your data?\"},\n",
    "{\"role\":\"user\",\"content\":\"no\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Alright, no machine learning. Could you tell me about the volume of your data? How much data do you have?\"},\n",
    "{\"role\":\"user\",\"content\":\"100GB\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Thanks for sharing. Now, could you tell me where your data currently resides? Is it in a database, a spreadsheet, or somewhere else?\"},\n",
    "{\"role\":\"user\",\"content\":\"Postgres\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Great, thanks for that information. Lastly, does your data need to be transformed (like cleaned, joined, etc.) before it can be visualized?\"},\n",
    "{\"role\":\"user\",\"content\":\"no\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Great! Based on your responses, I would recommend the following technologies: 1. Batch Ingestion: Since you need to access your data daily, batch ingestion would be a good fit. It allows you to collect data in batches and process it at a later time. 2. Data Warehouse: As your data is structured and stored in Postgres, a data warehouse would be suitable for storing and managing your data. 3. Visualization: Since you want to visualize your marketing data, a visualization tool would be necessary. Now, let's move on to the next step. When choosing vendors for these technologies, do you value ease of use, cost, or scalability/performance the most?\"},\n",
    "{\"role\":\"user\",\"content\":\"ease of use and cost\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Understood. Now, could you tell me what other tools your vendor recommendations will have to integrate with? Is there a specific cloud or on-premise vendor that you are working with?\"},\n",
    "{\"role\":\"user\",\"content\":\"AWS\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Great, AWS has a lot of integrated solutions. Do you prefer if the tools are cloud-native? If yes, is it important to have a tool that can support multi-cloud deployments?\"},\n",
    "{\"role\":\"user\",\"content\":\"Yes, but it does not matter if the tool supports multi-cloud deployments\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Understood. Lastly, could you tell me about the technical skills of your team? What languages do they know and which technologies do they have experience with?\"},\n",
    "{\"role\":\"user\",\"content\":\"SQL and python\"},\n",
    "{\"role\":\"assistant\",\"content\":\"Great! Based on your responses, here are my vendor recommendations: 1. Batch Ingestion: AWS Glue. It's a fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load your data for analytics. It's cost-effective and easy to use, especially if you're already on AWS. 2. Data Warehouse: Amazon Redshift. It's a fast, scalable data warehouse that makes it simple and cost-effective to analyze all your data using standard SQL and your existing business intelligence tools. 3. Visualization: Tableau. It's user-friendly, integrates well with AWS, and supports SQL and Python. It's also cost-effective. These tools should help you effectively visualize your marketing data. Let me know if you have any other questions!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (4177284820.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 29\u001b[0;36m\u001b[0m\n\u001b[0;31m    }\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "function_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"recommendations\":{\n",
    "            \"type\": \"array\",\n",
    "            \"properties\": {\n",
    "                \"technology\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"the type of technology that was recommended, e.g. Data Warehouse\",\n",
    "                },\n",
    "                \"vendors\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\":{\n",
    "                        \"name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"name of the vendor that was recommended, e.g. Snowflake\"\n",
    "                        },\n",
    "                        \"reasoning\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"why the vendor was recommended\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"reasoning\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"why the technology was recommended\"\n",
    "                }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_schema = \n",
    "{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"recommendations\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": \n",
    "        {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"tech\": {\"type\": \"string\"},\n",
    "            \"reasoning\": {\"type\": \"string\"},\n",
    "            \"vendors\": {\n",
    "              \"type\": \"array\",\n",
    "              \"items\": \n",
    "                {\n",
    "                  \"type\": \"object\",\n",
    "                  \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"reasoning\": {\"type\": \"string\"}\n",
    "                  },\n",
    "                  \"required\": [\"name\",\"reasoning\"]\n",
    "                }\n",
    "              \n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"tech\",\"reasoning\",\"vendors\"]\n",
    "        }\n",
    "      \n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"recommendations\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look at the chat history delimited by triple backticks. \n",
      "    Extract which technologies and vendors were recommended by the assistant. Also extract why each technology and vendor was recommended.\n",
      "    \n",
      "    '''\n",
      "    [{'role': 'assistant', 'content': \"Hello! I'm Archie the Architect. I can help you determine what technologies you need for your data architecture. Could you please tell me a bit about your project?\"}, {'role': 'user', 'content': 'i want to visualize my marketing data'}, {'role': 'assistant', 'content': 'That sounds like a great project! To start, could you please tell me what kind of data you are working with? Is it structured, semi-structured, or unstructured?'}, {'role': 'user', 'content': 'structured'}, {'role': 'assistant', 'content': \"Great! Structured data is easier to work with. Now, could you tell me about your latency requirements? In other words, how quickly do you need to access your data after it's been collected?\"}, {'role': 'user', 'content': 'daily'}, {'role': 'assistant', 'content': 'Understood. Now, are you planning on doing any predictive analytics, like machine learning, with your data?'}, {'role': 'user', 'content': 'no'}, {'role': 'assistant', 'content': 'Alright, no machine learning. Could you tell me about the volume of your data? How much data do you have?'}, {'role': 'user', 'content': '100GB'}, {'role': 'assistant', 'content': 'Thanks for sharing. Now, could you tell me where your data currently resides? Is it in a database, a spreadsheet, or somewhere else?'}, {'role': 'user', 'content': 'Postgres'}, {'role': 'assistant', 'content': 'Great, thanks for that information. Lastly, does your data need to be transformed (like cleaned, joined, etc.) before it can be visualized?'}, {'role': 'user', 'content': 'no'}, {'role': 'assistant', 'content': \"Great! Based on your responses, I would recommend the following technologies: 1. Batch Ingestion: Since you need to access your data daily, batch ingestion would be a good fit. It allows you to collect data in batches and process it at a later time. 2. Data Warehouse: As your data is structured and stored in Postgres, a data warehouse would be suitable for storing and managing your data. 3. Visualization: Since you want to visualize your marketing data, a visualization tool would be necessary. Now, let's move on to the next step. When choosing vendors for these technologies, do you value ease of use, cost, or scalability/performance the most?\"}, {'role': 'user', 'content': 'ease of use and cost'}, {'role': 'assistant', 'content': 'Understood. Now, could you tell me what other tools your vendor recommendations will have to integrate with? Is there a specific cloud or on-premise vendor that you are working with?'}, {'role': 'user', 'content': 'AWS'}, {'role': 'assistant', 'content': 'Great, AWS has a lot of integrated solutions. Do you prefer if the tools are cloud-native? If yes, is it important to have a tool that can support multi-cloud deployments?'}, {'role': 'user', 'content': 'Yes, but it does not matter if the tool supports multi-cloud deployments'}, {'role': 'assistant', 'content': 'Understood. Lastly, could you tell me about the technical skills of your team? What languages do they know and which technologies do they have experience with?'}, {'role': 'user', 'content': 'SQL and python'}, {'role': 'assistant', 'content': \"Great! Based on your responses, here are my vendor recommendations: 1. Batch Ingestion: AWS Glue. It's a fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load your data for analytics. It's cost-effective and easy to use, especially if you're already on AWS. 2. Data Warehouse: Amazon Redshift. It's a fast, scalable data warehouse that makes it simple and cost-effective to analyze all your data using standard SQL and your existing business intelligence tools. 3. Visualization: Tableau. It's user-friendly, integrates well with AWS, and supports SQL and Python. It's also cost-effective. These tools should help you effectively visualize your marketing data. Let me know if you have any other questions!\"}]\n",
      "    '''\n",
      "    \n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Invalid schema for function 'function_name': [{'type': 'object', 'properties': {'tech': {'type': 'string'}, 'reasoning': {'type': 'string'}, 'vendors': {'type': 'array', 'items': [{'type': 'object', 'properties': {'name': {'type': 'string'}, 'reasoning': {'type': 'string'}}, 'required': ['name', 'reasoning']}]}}, 'required': ['tech', 'reasoning', 'vendors']}] is not of type 'object', 'boolean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[39m=\u001b[39m create_extract_tech_prompt(chat_history)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(prompt)\n\u001b[0;32m----> 3\u001b[0m result \u001b[39m=\u001b[39m get_completion_with_function(prompt\u001b[39m=\u001b[39mprompt,function_schema\u001b[39m=\u001b[39mfunction_schema)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/Documents/LLMs/ArchitectAI/functions/get_completion_with_function.py:7\u001b[0m, in \u001b[0;36mget_completion_with_function\u001b[0;34m(prompt, function_schema, model, temperature)\u001b[0m\n\u001b[1;32m      5\u001b[0m openai\u001b[39m.\u001b[39mapi_key  \u001b[39m=\u001b[39m OPENAI_API_KEY\n\u001b[1;32m      6\u001b[0m messages \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt}]\n\u001b[0;32m----> 7\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      9\u001b[0m     messages\u001b[39m=\u001b[39mmessages,\n\u001b[1;32m     10\u001b[0m     temperature\u001b[39m=\u001b[39mtemperature,\n\u001b[1;32m     11\u001b[0m     functions\u001b[39m=\u001b[39m[{\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfunction_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mparameters\u001b[39m\u001b[39m\"\u001b[39m: function_schema}],\n\u001b[1;32m     12\u001b[0m     function_call\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfunction_name\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/chatbot/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/chatbot/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/chatbot/lib/python3.11/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/chatbot/lib/python3.11/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/chatbot/lib/python3.11/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Invalid schema for function 'function_name': [{'type': 'object', 'properties': {'tech': {'type': 'string'}, 'reasoning': {'type': 'string'}, 'vendors': {'type': 'array', 'items': [{'type': 'object', 'properties': {'name': {'type': 'string'}, 'reasoning': {'type': 'string'}}, 'required': ['name', 'reasoning']}]}}, 'required': ['tech', 'reasoning', 'vendors']}] is not of type 'object', 'boolean'"
     ]
    }
   ],
   "source": [
    "prompt = create_extract_tech_prompt(chat_history)\n",
    "print(prompt)\n",
    "result = get_completion_with_function(prompt=prompt,function_schema=function_schema)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_json = json.dumps(result)\n",
    "result_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import openai\n",
    "import streamlit as st\n",
    "\n",
    "def mm(graph):\n",
    "  graphbytes = graph.encode(\"ascii\")\n",
    "  base64_bytes = base64.b64encode(graphbytes)\n",
    "  base64_string = base64_bytes.decode(\"ascii\")\n",
    "  return \"https://mermaid.ink/img/\" + base64_string\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4\", temperature=0):\n",
    "    openai.api_key  = \"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\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "code = get_completion(\"\"\"generate mermaid code. Only generate code, do not include anything else in your response. In the code, all lines after the first should be indented. All node labels should be enclosed in square brackets and double quotes. For example, if you wanted node A to display `[Fe(CN)6]4-`, it should be written as `A[\"[Fe(CN)6]4-\"]`\"\"\")\n",
    "st.write(code)\n",
    "code = code.replace(\"`\",\"\").replace(\"mermaid\",\"\")\n",
    "url = mm(code)\n",
    "         \n",
    "st.image(image=url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
